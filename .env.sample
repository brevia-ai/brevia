### Secrets that must be available as environment variables
# You can define here secrets used by LLM API services (api keys or access tokens for instance)
# and by other third party services that need specific env variables.
# If you don't set these variables, the services that depend on them may not work properly.
# By using BREVIA_ENV_SECRETS you make sure that these secrets will be available as environment variables.
# BREVIA_ENV_SECRETS='{"OPENAI_API_KEY": "#########", "COHERE_API_KEY": "#########"}'

## OpenAI, Cohere, and other API secrets
# If these vars are not available as environment variables you may want to add them to BREVIA_ENV_SECRETS (see above)
# OPENAI_API_KEY=#########
# COHERE_API_KEY=#########

## Tracing - Langsmith: if you have an account you need the env vars listed below, edit API_KEY and PROJECT vars
# If these vars are not available as environment variables you may want to add them to BREVIA_ENV_SECRETS (see above)
# LANGCHAIN_TRACING_V2=true
# LANGCHAIN_ENDPOINT="https://api.smith.langchain.com"
# LANGCHAIN_API_KEY="########"
# LANGCHAIN_PROJECT="My Project"

### QA vars
# Completion LLM configuration
# QA_COMPLETION_LLM='{"model_provider": "openai", "model": "gpt-4o-mini", "temperature": 0, "max_tokens": 200, "verbose": true}'

# Followup LLM configuration
# QA_FOLLOWUP_LLM='{"model_provider": "openai", "model": "gpt-4o-mini", "temperature": 0, "max_tokens": 200, "verbose": true}'

# Followup similarity threshold
# QA_FOLLOWUP_SIM_THRESHOLD=0.735

# Chat history - uncomment to disable session conversation, avoiding chat history loading
# QA_NO_CHAT_HISTORY=True

# Uncomment to use a custom QA retriever with custom arguments
# QA_RETRIEVER='{"retriever": "my_project.CustomRetriever", "some_var": "some_value"}'

### Security
# Access tokens secret - if missing no access token validity is checked
# Generate it with: openssl rand -hex 32
# TOKENS_SECRET=##########################
# Comma separated list of valid users - use double quotes!
# TOKENS_USERS="brevia,gustavo"

## Status
# Special token used by `GET /status` only
# STATUS_TOKEN=#############

### Search
# default number of documents to return in a vector search
# SEARCH_DOCS_NUM=4

### Embedding
# Embeddings engine configuration
# EMBEDDINGS='{"_type": "openai-embeddings"}'

### Index creation
# TEXT_CHUNK_SIZE=2000
# TEXT_CHUNK_OVERLAP=100
# Uncomment to use a custom splitter with custom arguments
# TEXT_SPLITTER='{"splitter": "my_project.CustomSplitter", "some_var": "some_value"}'

### Summarize
# Summarization LLM
# SUMMARIZE_LLM='{"model_provider": "openai", "model": "gpt-4o-mini", "temperature": 0, "max_tokens": 2000}'
# SUMM_TOKEN_SPLITTER=4000
# SUMM_TOKEN_OVERLAP=500
# SUMM_DEFAULT_CHAIN=stuff

### Providers
# Uncomment to customize the list of known providers environment variables that could be used by external services (mainly LLM providers)
# PROVIDERS_ENV_VARS = '{"openai": ["OPENAI_API_KEY","OPENAI_ORG_ID","OPENAI_API_BASE"], "anthropic": ["ANTHROPIC_API_KEY"], "cohere": ["COHERE_API_KEY"], "deepseek": ["DEEPSEEK_API_KEY"], "ollama": ["OLLAMA_HOST"]}'

### General
# VERBOSE_MODE=True

### OPENAPI
# Uncomment to block openapi urls - /docs, /redoc
# BLOCK_OPENAPI_URLS=True

### Database connection
# PGVECTOR_DRIVER=psycopg2
# host var is used on local development
# but ignored by docker compose
# PGVECTOR_HOST=localhost
# PGVECTOR_PORT=5432
# PGVECTOR_DATABASE=brevia
# PGVECTOR_USER=postgres
# PGVECTOR_PASSWORD=postgres
# PGVECTOR_POOL_SIZE=10

### Docker compose
## Postgres pgvector
# PGVECTOR_VOLUME_NAME=pgdata
## PG ADMIN
# PGADMIN_DEFAULT_EMAIL=admin@admin.com
# PGADMIN_DEFAULT_PASSWORD=admin
# PGADMIN_PORT=4000
# PGADMIN_VOLUME_NAME=pgadmindata
## BREVIA API
# BREVIA_API_PORT=8000
# BREVIA_API_VOLUME_NAME=breviaapidata
## BREVIA APP
# BREVIA_APP_PORT=3000
# BREVIA_APP_VOLUME_NAME=breviaappdata

## File output options - uncomment to enable
## `FILE_OUTPUT_BASE_PATH` can be a local filesystem path or an S3 path like s3://my-bucket/path
# FILE_OUTPUT_BASE_PATH=/var/www/brevia/files
## `FILE_OUTPUT_BASE_URL` is the base URL used to access files, if omitted the files will be served via the `/download` endpoint,
##  when using S3, the files can be served via the S3 URL, something like: https://my-bucket.s3.{region}.amazonaws.com/path
# FILE_OUTPUT_BASE_URL=https://example.com/download
