### Secrets that must be available as environment variables
# You can define here secrets used by LLM API services (api keys or access tokens for instance)
# and by other third party services that need specific env variables.
# If you don't set these variables, the services that depend on them may not work properly.
# By using BREVIA_ENV_SECRETS you make sure that these secrets will be available as environment variables.
# BREVIA_ENV_SECRETS='{"OPENAI_API_KEY": "#########", "COHERE_API_KEY": "#########"}'

## OpenAI, Cohere, and other API secrets
# If these vars are not available as environment variables you may want to add them to BREVIA_ENV_SECRETS (see above)
# OPENAI_API_KEY=#########
# COHERE_API_KEY=#########

## Tracing - Langsmith: if you have an account you need the env vars listed below, edit API_KEY and PROJECT vars
# If these vars are not available as environment variables you may want to add them to BREVIA_ENV_SECRETS (see above)
# LANGCHAIN_TRACING_V2=true
# LANGCHAIN_ENDPOINT="https://api.smith.langchain.com"
# LANGCHAIN_API_KEY="########"
# LANGCHAIN_PROJECT="My Project"


### QA vars
# Completion LLM configuration
# QA_COMPLETION_LLM='{"_type": "openai-chat", "model_name": "gpt-4o-mini", "temperature": 0, "max_tokens": 200, "verbose": true}'

# Followup LLM configuration
# QA_FOLLOWUP_LLM='{"_type": "openai-chat", "model_name": "gpt-4o-mini", "temperature": 0, "max_tokens": 200, "verbose": true}'

# Followup similarity threshold
# QA_FOLLOWUP_SIM_THRESHOLD=0.735

# Chat history - uncomment to disable session conversation, avoiding chat history loading
# QA_NO_CHAT_HISTORY=True

# Uncomment to use a custom QA retriever with custom arguments
# QA_RETRIEVER='{"retriever": "my_project.CustomRetriever", "some_var": "some_value"}'

### Security
# Access tokens secret - if missing no access token validity is checked
# Generate it with: openssl rand -hex 32
# TOKENS_SECRET=##########################
# Comma separated list of valid users - use double quotes!
# TOKENS_USERS="brevia,gustavo"

## Status
# Special token used by `GET /status` only
# STATUS_TOKEN=#############


### Search
# default number of documents to return in a vector search
# SEARCH_DOCS_NUM=4


### Embedding
# Embeddings engine configuration
# EMBEDDINGS='{"_type": "openai-embeddings"}'

### Index creation
# TEXT_CHUNK_SIZE=2000
# TEXT_CHUNK_OVERLAP=100
# Uncomment to use a custom splitter with custom arguments
# TEXT_SPLITTER='{"splitter": "my_project.CustomSplitter", "some_var": "some_value"}'


### Summarize
# Summarization LLM
# SUMMARIZE_LLM='{"_type": "openai-chat", "model_name": "gpt-4o-mini", "temperature": 0, "max_tokens": 2000}'
# SUMM_TOKEN_SPLITTER=4000
# SUMM_TOKEN_OVERLAP=500
# SUMM_DEFAULT_CHAIN=stuff


### General
# VERBOSE_MODE=True


### OPENAPI
# Uncomment to block openapi urls - /docs, /redoc
# BLOCK_OPENAPI_URLS=True


### Database connection
# PGVECTOR_DRIVER=psycopg2
# host var is used on local development
# but ignored by docker compose
# PGVECTOR_HOST=localhost
# PGVECTOR_PORT=5432
# PGVECTOR_DATABASE=brevia
PGVECTOR_USER=postgres
PGVECTOR_PASSWORD=postgres
# PGVECTOR_POOL_SIZE=10

### Docker compose
# PGVECTOR_VOLUME_NAME=pgvector-data
## PG ADMIN
# PGADMIN_DEFAULT_EMAIL=admin@admin.com
# PGADMIN_DEFAULT_PASSWORD=admin
# PGADMIN_PORT=4000
# PGADMIN_VOLUME_NAME=pgadmin-data


